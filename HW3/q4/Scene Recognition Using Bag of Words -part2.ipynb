{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nic-uufix1Gf"
      },
      "source": [
        "##**mount drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtV694ZSxwGs",
        "outputId": "f2b12f43-71dc-446e-cf4a-6dbb9c5a9e09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfcgSBrcx4YG"
      },
      "source": [
        "##**unzip dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6o33DNfBx7Op"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os \n",
        "os.chdir(\"/content\")\n",
        "path_of_zip_file=\"/content/gdrive/MyDrive/vision_dataset/Data.zip\"\n",
        "\n",
        "with zipfile.ZipFile(path_of_zip_file, 'r') as zip_ref:\n",
        "      zip_ref.extractall(\"/content\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uV2U2ZvPQpA8"
      },
      "source": [
        "##**Import required libraries**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQFWDFKMQt6t",
        "outputId": "66300eba-35c8-4559-bb53-c3ffff278d44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opencv-contrib-python==4.4.0.44\n",
            "  Downloading opencv_contrib_python-4.4.0.44-cp37-cp37m-manylinux2014_x86_64.whl (55.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 55.7 MB 235 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-contrib-python==4.4.0.44) (1.21.6)\n",
            "Installing collected packages: opencv-contrib-python\n",
            "  Attempting uninstall: opencv-contrib-python\n",
            "    Found existing installation: opencv-contrib-python 4.1.2.30\n",
            "    Uninstalling opencv-contrib-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-contrib-python-4.1.2.30\n",
            "Successfully installed opencv-contrib-python-4.4.0.44\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-contrib-python==4.4.0.44\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJE70dDYx97J"
      },
      "source": [
        "##**part B : BOW and k_means**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fX_V96ZyJn9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import glob\n",
        "import os\n",
        "\n",
        "sift = cv2.SIFT_create()\n",
        "lenght_vector=np.zeros([2985])\n",
        "features_space=np.zeros([0,128])\n",
        "k_means_feature=np.zeros([0,128])\n",
        "label_list=[]\n",
        "path_of_train_set=\"/content/Data/Train\"\n",
        "j=-1\n",
        "#iterate all over train_set\n",
        "for i,(root, dirs, files) in enumerate(os.walk(path_of_train_set)):\n",
        "    if(i!=0):\n",
        "       label = str(root).split(\"/\")[-1]\n",
        "       for name in glob.glob(f'{root}/*.jpg'):\n",
        "          j+=1\n",
        "          # label_list.append(label)\n",
        "          if(j//5==0):\n",
        "            image=cv2.imread(str(name), cv2.IMREAD_GRAYSCALE)\n",
        "            kp1, des1 = sift.detectAndCompute(image,None)\n",
        "            k_means_feature=np.concatenate((k_means_feature,des1), axis=0)\n",
        "          else :\n",
        "             continue  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUtcDhKv59RR"
      },
      "source": [
        "##**using k_means for ectract dictionaty words** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puvU-jl0a_9D"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "kmeans = KMeans(n_clusters=100,init='k-means++',max_iter=300, random_state=0).fit(k_means_feature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDpmo2OHdf8g"
      },
      "outputs": [],
      "source": [
        "print(kmeans.cluster_centers_)\n",
        "print(kmeans.cluster_centers_.shape)\n",
        "print(kmeans.labels_)\n",
        "print(kmeans.labels_.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkOy8mZo5z2g"
      },
      "source": [
        "##**Make train_set histogram**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aJNbhKz9yBPN"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "neigh = NearestNeighbors(n_neighbors=1)\n",
        "neigh.fit(kmeans.cluster_centers_)\n",
        "label_list=[]\n",
        "label_of_train_data_set=[]\n",
        "\n",
        "hist_train=np.zeros([2985,100]).astype(np.float16)\n",
        "j=-1\n",
        "start_index=0\n",
        "\n",
        "for i,(root, dirs, files) in enumerate(os.walk(path_of_train_set)):\n",
        "    if(i!=0):\n",
        "\n",
        "       label = str(root).split(\"/\")[-1]\n",
        "       label_list.append(label)\n",
        "       for name in glob.glob(f'{root}/*.jpg'):\n",
        "          j+=1\n",
        "          label_of_train_data_set.append(i)\n",
        "          image=cv2.imread(str(name), cv2.IMREAD_GRAYSCALE)\n",
        "          kp1, des1 = sift.detectAndCompute(image,None)\n",
        "          labels=neigh.kneighbors(des1, return_distance=False)\n",
        "          for lebel in labels:\n",
        "             hist_train[j,int(lebel)]+=1\n",
        "          hist_train[j,:]=hist_train[j,:]/des1.shape[0]   \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGnum1sQ0Icb"
      },
      "outputs": [],
      "source": [
        "print(hist_train[10])\n",
        "print(np.sum(hist_train[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGbjjIyudv2B"
      },
      "source": [
        "##**Make Histogram of test set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQQ8d5pOT-1-"
      },
      "outputs": [],
      "source": [
        "path_of_test_set=\"/content/Data/Test\"\n",
        "hist_test=np.zeros([1500,100]).astype(np.float16)\n",
        "label_of_test_data_set=[]\n",
        "j=-1\n",
        "for i,(root, dirs, files) in enumerate(os.walk(path_of_test_set)):\n",
        "    if(i!=0):\n",
        "       for name in glob.glob(f'{root}/*.jpg'):\n",
        "          label_of_test_data_set.append(i)\n",
        "          j+=1\n",
        "          image=cv2.imread(str(name), cv2.IMREAD_GRAYSCALE)\n",
        "          kp1, des1 = sift.detectAndCompute(image,None)\n",
        "          labels=neigh.kneighbors(des1, return_distance=False)\n",
        "          for lebel in labels:\n",
        "             hist_test[j,int(lebel)]+=1\n",
        "          hist_test[j,:]=hist_test[j,:]/des1.shape[0]   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4mYriPvKt_H"
      },
      "outputs": [],
      "source": [
        "print(hist_test[1])\n",
        "print(np.sum(hist_test[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5QFKaG3ZN-C"
      },
      "source": [
        "#**Measure acc**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z99EBMjdZQ_Q",
        "outputId": "92165a6d-b480-43c8-88d4-80e3d501b55c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38.46666666666667\n"
          ]
        }
      ],
      "source": [
        "from sklearn import metrics\n",
        "k=11\n",
        "true_predication=0\n",
        "neigh = NearestNeighbors(n_neighbors=k,metric='manhattan')\n",
        "neigh.fit(hist_train)\n",
        "NearestNeighbors(n_neighbors=k)\n",
        "indice=neigh.kneighbors(hist_test)\n",
        "\n",
        "for i,k_nearest in enumerate(indice[1][:]) :\n",
        "\n",
        "   candidat_labels=[label_of_train_data_set[i] for i in k_nearest]\n",
        "   prediceted_label=np.median(candidat_labels)\n",
        "\n",
        "   if(label_of_test_data_set[i]==prediceted_label):\n",
        "       true_predication+=1\n",
        "    \n",
        "acc=float(true_predication/1500)      \n",
        "print(acc*100)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "q4_hw03_part_B.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}